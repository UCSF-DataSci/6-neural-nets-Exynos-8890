{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe04f973",
   "metadata": {},
   "source": [
    "# Part 2: CNN Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd0aa93",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this part, you'll implement a Convolutional Neural Network (CNN) for EMNIST character recognition. You can choose between TensorFlow/Keras or PyTorch for implementation. This will help you understand CNNs and their advantages for image classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc223613",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "- Implement a CNN using either TensorFlow/Keras or PyTorch\n",
    "- Apply convolutional layers, pooling, and batch normalization\n",
    "- Train and evaluate the model\n",
    "- Save model and metrics in the correct format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba2e17c",
   "metadata": {},
   "source": [
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7ade46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure matplotlib for better visualization\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('results/part_2', exist_ok=True)\n",
    "os.makedirs('logs', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddbb458",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a51260aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 11:54:55.007970: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2025-05-14 11:54:55.008019: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-05-14 11:54:55.008028: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1747248895.008326 15040604 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1747248895.008353 15040604 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-05-14 11:54:55.496503: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:387] The default buffer size is 262144, which is overridden by the user specified `buffer_size` of 8388608\n",
      "2025-05-14 11:54:55.613137: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-05-14 11:54:55.796812: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.00784314, 0.01176471,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.00784314, 0.25490198, 0.41568628,\n",
       "         0.07058824, 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.08235294, 0.6627451 , 0.8235294 ,\n",
       "         0.14509805, 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.19607843, 0.8627451 , 0.8509804 ,\n",
       "         0.14509805, 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.01568628, 0.44705883, 0.9607843 , 0.8509804 ,\n",
       "         0.14509805, 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.01568628, 0.49803922, 0.9764706 , 0.8       ,\n",
       "         0.1254902 , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.01568628, 0.00784314,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.03137255, 0.54509807, 0.96862745, 0.59607846,\n",
       "         0.05098039, 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.1254902 , 0.44313726, 0.24705882,\n",
       "         0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.0627451 , 0.627451  , 0.9764706 , 0.6745098 ,\n",
       "         0.08235294, 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.01176471, 0.14117648, 0.6862745 , 0.9843137 , 0.49803922,\n",
       "         0.01568628, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.1254902 , 0.8       , 0.9843137 , 0.6666667 ,\n",
       "         0.07843138, 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.07843138,\n",
       "         0.3254902 , 0.6862745 , 0.9647059 , 0.99607843, 0.44705883,\n",
       "         0.01568628, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.19607843, 0.87058824, 0.9607843 , 0.4509804 ,\n",
       "         0.01568628, 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.01176471, 0.09411765, 0.49803922,\n",
       "         0.9019608 , 0.9882353 , 0.99607843, 0.95686275, 0.18039216,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.01568628, 0.44705883, 0.9607843 , 0.87058824, 0.2       ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.03137255, 0.30980393, 0.67058825, 0.91764706,\n",
       "         0.99607843, 1.        , 0.9882353 , 0.69411767, 0.02745098,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.03529412, 0.54901963, 0.98039216, 0.84313726, 0.14509805,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.07843138, 0.37254903, 0.85490197, 0.9843137 , 0.96862745,\n",
       "         0.8901961 , 0.9764706 , 0.9607843 , 0.4509804 , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.1254902 , 0.8       , 0.9843137 , 0.6745098 , 0.08235294,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.03921569,\n",
       "         0.48235294, 0.90588236, 0.98039216, 0.9098039 , 0.62352943,\n",
       "         0.32941177, 0.87058824, 0.87058824, 0.2       , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "         0.20392157, 0.87058824, 0.98039216, 0.5058824 , 0.01960784,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.00784314, 0.3019608 ,\n",
       "         0.8627451 , 0.9843137 , 0.73333335, 0.32941177, 0.08627451,\n",
       "         0.15294118, 0.8509804 , 0.8509804 , 0.14509805, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.07843138,\n",
       "         0.62352943, 0.96862745, 0.9607843 , 0.44705883, 0.01568628,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.03529412, 0.54509807,\n",
       "         0.9764706 , 0.8627451 , 0.3137255 , 0.01568628, 0.        ,\n",
       "         0.14509805, 0.8509804 , 0.8509804 , 0.14509805, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.14901961,\n",
       "         0.84705883, 0.99215686, 0.8156863 , 0.18039216, 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.18039216, 0.8156863 ,\n",
       "         0.9764706 , 0.54509807, 0.04313726, 0.        , 0.        ,\n",
       "         0.14509805, 0.8509804 , 0.8509804 , 0.15294118, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.01568628, 0.32941177,\n",
       "         0.9137255 , 0.98039216, 0.54509807, 0.03529412, 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.01568628, 0.44705883, 0.9607843 ,\n",
       "         0.9137255 , 0.32156864, 0.00784314, 0.        , 0.        ,\n",
       "         0.14509805, 0.8509804 , 0.9137255 , 0.32156864, 0.        ,\n",
       "         0.        , 0.        , 0.00784314, 0.25882354, 0.73333335,\n",
       "         0.9843137 , 0.9137255 , 0.32156864, 0.00784314, 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.08235294, 0.6745098 , 0.9843137 ,\n",
       "         0.8       , 0.1254902 , 0.        , 0.        , 0.        ,\n",
       "         0.07843138, 0.62352943, 0.9607843 , 0.6745098 , 0.01176471,\n",
       "         0.        , 0.        , 0.13333334, 0.69411767, 0.9882353 ,\n",
       "         0.9843137 , 0.6666667 , 0.08235294, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.1254902 , 0.7921569 , 0.98039216,\n",
       "         0.54901963, 0.03529412, 0.        , 0.        , 0.        ,\n",
       "         0.00392157, 0.20392157, 0.87058824, 0.9098039 , 0.20784314,\n",
       "         0.14509805, 0.16078432, 0.5176471 , 0.95686275, 0.99607843,\n",
       "         0.8627451 , 0.30980393, 0.01176471, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.03921569, 0.5568628 , 0.9647059 ,\n",
       "         0.49803922, 0.01568628, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.1254902 , 0.7882353 , 0.98039216, 0.87058824,\n",
       "         0.8509804 , 0.85490197, 0.9254902 , 0.99215686, 0.9490196 ,\n",
       "         0.49803922, 0.03921569, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.08235294, 0.6745098 , 0.96862745,\n",
       "         0.49803922, 0.01568628, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.02745098, 0.30980393, 0.73333335, 0.99215686,\n",
       "         0.99607843, 0.99607843, 0.9882353 , 0.9098039 , 0.5137255 ,\n",
       "         0.1254902 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.14117648, 0.8392157 , 0.9764706 ,\n",
       "         0.49803922, 0.01568628, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.01568628, 0.2627451 , 0.79607844,\n",
       "         0.8509804 , 0.84313726, 0.6745098 , 0.43137255, 0.08627451,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.08235294, 0.6666667 , 0.9529412 ,\n",
       "         0.49019608, 0.01568628, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.00784314, 0.1254902 ,\n",
       "         0.14509805, 0.14509805, 0.08235294, 0.01568628, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.00784314, 0.25490198, 0.47843137,\n",
       "         0.24705882, 0.00784314, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.00784314, 0.01568628,\n",
       "         0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ]]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load EMNIST dataset\n",
    "# import tensorflow_datasets as tfds\n",
    "# (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data('letters')\n",
    "import tensorflow_datasets as tfds\n",
    "(train, test), dataset_info = tfds.load(\n",
    "  'emnist/byclass',\n",
    "  split=['train', 'test'],\n",
    "  as_supervised=True,\n",
    "  with_info=True,\n",
    ")\n",
    "def preprocess_images(image, label):\n",
    "    # Convert to float and normalize to [0, 1]\n",
    "    # This is important because neural networks work better with normalized data\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.image.flip_left_right(image)\n",
    "    image = tf.image.rot90(image)\n",
    "    return image, label\n",
    "train = train.map(preprocess_images)\n",
    "test = test.map(preprocess_images)\n",
    "x_train = []\n",
    "y_train = []\n",
    "for image, label in tfds.as_numpy(train.take(1000)):\n",
    "    x_train.append(image)\n",
    "    y_train.append(label)\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "for image, label in tfds.as_numpy(test.take(1000)):\n",
    "    x_test.append(image)\n",
    "    y_test.append(label)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "temp = x_train[0].T\n",
    "display(temp)\n",
    "display(temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8af7702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1000, 28, 28, 1)\n",
      "Test data shape: (1000, 28, 28, 1)\n",
      "Number of classes: 62\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Training data shape: {x_train.shape}\")\n",
    "print(f\"Test data shape: {x_test.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_train))}\")\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    k =np.random.randint(0, len(x_train) - 1)\n",
    "    plt.imshow(x_train[k], cmap='gray')\n",
    "    plt.title(f'Label: {chr(y_train[k] + (ord('0') if y_train[k] < 10 else( ord(\"A\") - 10 if y_train[k] < 36 else ord(\"a\") - 36)))}')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743848d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "# Normalize pixel values\n",
    "# x_train = x_train.astype('float32') / 255.0\n",
    "# x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Reshape for CNN input (samples, height, width, channels)\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train - 1, num_classes=26)\n",
    "y_test = tf.keras.utils.to_categorical(y_test - 1, num_classes=26)\n",
    "\n",
    "# Split training data into train and validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train, y_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Preprocessed training data shape: {x_train.shape}\")\n",
    "print(f\"Preprocessed validation data shape: {x_val.shape}\")\n",
    "print(f\"Preprocessed test data shape: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef9205e",
   "metadata": {},
   "source": [
    "## 2. Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4791c08b",
   "metadata": {},
   "source": [
    "### TensorFlow/Keras Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d698a258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CNN using Keras\n",
    "def create_cnn_keras(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Create a CNN using TensorFlow/Keras.\n",
    "    \n",
    "    Requirements:\n",
    "    - Must use at least 2 convolutional layers\n",
    "    - Must include pooling and batch normalization\n",
    "    - Must use categorical crossentropy loss\n",
    "    \n",
    "    Goals:\n",
    "    - Achieve > 85% accuracy on test set\n",
    "    - Minimize overfitting using batch normalization and dropout\n",
    "    - Train efficiently with appropriate batch size and learning rate\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Shape of input data (should be (28, 28, 1) for grayscale images)\n",
    "        num_classes: Number of output classes (26 for letters)\n",
    "    \n",
    "    Returns:\n",
    "        Compiled Keras model\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential([...])\n",
    "    \n",
    "    model.compile(...)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create and compile model\n",
    "model = create_cnn_keras(input_shape=(28, 28, 1), num_classes=26)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd55700",
   "metadata": {},
   "source": [
    "### PyTorch Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947a1179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        \"\"\"\n",
    "        Create a CNN using PyTorch.\n",
    "        \n",
    "        Requirements:\n",
    "        - Must use at least 2 convolutional layers\n",
    "        - Must include pooling and batch normalization\n",
    "        \n",
    "        Goals:\n",
    "        - Achieve > 85% accuracy on test set\n",
    "        - Minimize overfitting using batch normalization and dropout\n",
    "        - Train efficiently with appropriate batch size and learning rate\n",
    "        \n",
    "        Args:\n",
    "            num_classes: Number of output classes (26 for letters)\n",
    "        \"\"\"\n",
    "        super(CNN, self).__init__()\n",
    "        [...]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the network.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, channels, height, width)\n",
    "        \n",
    "        Returns:\n",
    "            Output tensor of shape (batch_size, num_classes)\n",
    "        \"\"\"\n",
    "        [...]\n",
    "        return x\n",
    "\n",
    "# Create model\n",
    "model = CNN(num_classes=26)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010b05fa",
   "metadata": {},
   "source": [
    "## 3. Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91536c73",
   "metadata": {},
   "source": [
    "### TensorFlow/Keras Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e24df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=3\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        'models/cnn_keras.keras',\n",
    "        save_best_only=True\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Plot training curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot accuracy\n",
    "ax1.plot(history.history['accuracy'], label='Training')\n",
    "ax1.plot(history.history['val_accuracy'], label='Validation')\n",
    "ax1.set_title('Model Accuracy')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot loss\n",
    "ax2.plot(history.history['loss'], label='Training')\n",
    "ax2.plot(history.history['val_loss'], label='Validation')\n",
    "ax2.set_title('Model Loss')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4c9346",
   "metadata": {},
   "source": [
    "### PyTorch Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5699b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model to device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "x_train = torch.FloatTensor(x_train).to(device)\n",
    "y_train = torch.LongTensor(np.argmax(y_train, axis=1)).to(device)\n",
    "x_val = torch.FloatTensor(x_val).to(device)\n",
    "y_val = torch.LongTensor(np.argmax(y_val, axis=1)).to(device)\n",
    "\n",
    "# Training loop\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "best_val_loss = float('inf')\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(20):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    for i in range(0, len(x_train), 32):\n",
    "        batch_x = x_train[i:i+32]\n",
    "        batch_y = y_train[i:i+32]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        train_total += batch_y.size(0)\n",
    "        train_correct += predicted.eq(batch_y).sum().item()\n",
    "    \n",
    "    train_loss = train_loss / (len(x_train) / 32)\n",
    "    train_acc = train_correct / train_total\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(x_val), 32):\n",
    "            batch_x = x_val[i:i+32]\n",
    "            batch_y = y_val[i:i+32]\n",
    "            \n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_total += batch_y.size(0)\n",
    "            val_correct += predicted.eq(batch_y).sum().item()\n",
    "    \n",
    "    val_loss = val_loss / (len(x_val) / 32)\n",
    "    val_acc = val_correct / val_total\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        # Save best model\n",
    "        torch.save(model.state_dict(), 'models/cnn_pytorch.pt')\n",
    "        # Save architecture\n",
    "        with open('models/cnn_pytorch_arch.txt', 'w') as f:\n",
    "            f.write(str(model))\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            break\n",
    "\n",
    "# Plot training curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot accuracy\n",
    "ax1.plot(history['train_acc'], label='Training')\n",
    "ax1.plot(history['val_acc'], label='Validation')\n",
    "ax1.set_title('Model Accuracy')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot loss\n",
    "ax2.plot(history['train_loss'], label='Training')\n",
    "ax2.plot(history['val_loss'], label='Validation')\n",
    "ax2.set_title('Model Loss')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c50849",
   "metadata": {},
   "source": [
    "## Progress Checkpoints\n",
    "\n",
    "1. **Data Loading**:\n",
    "   - [ ] Successfully load EMNIST dataset\n",
    "   - [ ] Verify data shapes and ranges\n",
    "   - [ ] Visualize sample images\n",
    "\n",
    "2. **Preprocessing**:\n",
    "   - [ ] Normalize pixel values\n",
    "   - [ ] Reshape data for CNN input\n",
    "   - [ ] Convert labels to one-hot encoding\n",
    "\n",
    "3. **Model Implementation**:\n",
    "   - [ ] Create CNN with required layers\n",
    "   - [ ] Verify architecture requirements\n",
    "   - [ ] Test model with sample input\n",
    "\n",
    "4. **Training**:\n",
    "   - [ ] Train model with callbacks\n",
    "   - [ ] Monitor training progress\n",
    "   - [ ] Save best model\n",
    "\n",
    "5. **Evaluation**:\n",
    "   - [ ] Calculate performance metrics\n",
    "   - [ ] Save metrics in correct format\n",
    "   - [ ] Visualize results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6cddf9",
   "metadata": {},
   "source": [
    "## Common Issues and Solutions\n",
    "\n",
    "1. **Data Loading Issues**:\n",
    "   - Problem: EMNIST dataset not found\n",
    "   - Solution: Check internet connection and TensorFlow installation\n",
    "\n",
    "2. **Preprocessing Issues**:\n",
    "   - Problem: Shape mismatch in CNN layers\n",
    "   - Solution: Ensure data is properly shaped (samples, height, width, channels)\n",
    "   - Problem: Label encoding errors\n",
    "   - Solution: Verify label range and one-hot encoding\n",
    "\n",
    "3. **Model Issues**:\n",
    "   - Problem: Training instability\n",
    "   - Solution: Add batch normalization, reduce learning rate\n",
    "   - Problem: Overfitting\n",
    "   - Solution: Increase dropout, use data augmentation\n",
    "\n",
    "4. **Evaluation Issues**:\n",
    "   - Problem: Metrics format incorrect\n",
    "   - Solution: Follow the exact format specified\n",
    "   - Problem: Performance below threshold\n",
    "   - Solution: Adjust architecture, hyperparameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
